{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import resource\n",
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import dgl\n",
    "import dgl.nn as dglnn\n",
    "import time\n",
    "import json\n",
    "from torch_geometric.utils import negative_sampling\n",
    "from torch_geometric.seed import seed_everything\n",
    "import torch.multiprocessing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tqdm\n",
    "import networkx as nx\n",
    "\n",
    "from combsage.combsage import IDRSAGEJK\n",
    "from combsage.graphsage import SAGE\n",
    "\n",
    "from combsage.utils import evaluate, convert_to_heterograph_group_isolates\n",
    "from combsage.utils import HetEdgePredictionSampler, HomoNeighborSampler\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(year): \n",
    "    \n",
    "    # load graph\n",
    "    G = nx.read_gexf('citation_graphs/{}.gexf'.format(year))\n",
    "    G_i = nx.convert_node_labels_to_integers(G, label_attribute='paper_id')\n",
    "    \n",
    "    # load embeddings\n",
    "    with open('scibert_embeddings.json') as infile:\n",
    "        emb = json.load(infile)\n",
    "    emb = pd.Series(emb)\n",
    "\n",
    "    # get embedding subset as matrix\n",
    "    node_df = pd.DataFrame.from_dict(dict(G_i.nodes(data=True)), orient='index')\n",
    "    X = np.vstack(emb.loc[node_df.paper_id].values)\n",
    "    \n",
    "    # get source and target vectors to create dgl graph \n",
    "    edge_list = nx.to_pandas_edgelist(G_i)\n",
    "    src = edge_list['source'].to_numpy()\n",
    "    dst = edge_list['target'].to_numpy()\n",
    "\n",
    "    # create dgl graph -- add attributes\n",
    "    g = dgl.graph((src,dst))\n",
    "    g.ndata['feat'] = torch.tensor(X).float()\n",
    "    \n",
    "    return node_df,g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {'r1': 15, 'r2': 10, 'lr': 0.0001, 'batch_size': 256, 'dropout':0.1}\n",
    "year = 2014"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_df,g = load_data(year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_edge_index = negative_sampling(edge_index=torch.vstack(g.edges()),\n",
    "                                num_nodes=g.number_of_nodes(), \n",
    "                                num_neg_samples=g.number_of_edges())\n",
    "\n",
    "u, v = g.edges()\n",
    "\n",
    "eids = np.arange(g.number_of_edges())\n",
    "eids = np.random.permutation(eids)\n",
    "val_size = int(len(eids) * 0.1)\n",
    "val_pos_u, val_pos_v = u[eids[:val_size]], v[eids[:val_size]]\n",
    "\n",
    "# Find all negative edges and split them for training and testing\n",
    "neg_u, neg_v = neg_edge_index[0], neg_edge_index[1]\n",
    "\n",
    "neg_eids = np.random.choice(len(neg_u), g.number_of_edges())\n",
    "val_neg_u, val_neg_v = neg_u[neg_eids[:val_size]], neg_v[neg_eids[:val_size]]\n",
    "\n",
    "val_pos_g = dgl.graph((val_pos_u, val_pos_v), num_nodes=g.number_of_nodes())\n",
    "val_neg_g = dgl.graph((val_neg_u, val_neg_v), num_nodes=g.number_of_nodes())\n",
    "\n",
    "train_g = dgl.remove_edges(g, eids[:val_size])\n",
    "\n",
    "edge_list = pd.DataFrame(torch.vstack(train_g.edges()).T)\n",
    "edge_list.columns = ['source', 'target']\n",
    "G = nx.from_pandas_edgelist(edge_list)\n",
    "g_hetero = convert_to_heterograph_group_isolates(G, n_nodes = train_g.number_of_nodes()).to(device)\n",
    "\n",
    "n_types = max([int(t) for t in g_hetero.etypes])\n",
    "e_tensors = [g_hetero.edges(etype = etype) for etype in sorted(g_hetero.etypes, key = int)]\n",
    "src = torch.hstack([e[0] for e in e_tensors])\n",
    "dst = torch.hstack([e[1] for e in e_tensors])\n",
    "\n",
    "g_homo = dgl.heterograph({('paper','1','paper'):(src,dst)})\n",
    "g_hetero.ndata['feat'] = train_g.ndata['feat']\n",
    "g_hetero.ndata['feat'] = g_hetero.ndata['feat']\n",
    "\n",
    "g_homo.to(device)\n",
    "g_hetero.to(device)\n",
    "\n",
    "del train_g \n",
    "del edge_list\n",
    "del G\n",
    "del src \n",
    "del dst\n",
    "del g\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = IDRSAGEJK(g_hetero.ndata['feat'].shape[1], 256,\n",
    "            n_types, dropout = config['dropout'])\n",
    "model.to(device)\n",
    "\n",
    "opt = torch.optim.Adam(model.parameters(), lr=config['lr'])\n",
    "edge_dict = {etype: g_hetero.edges(etype = etype, form = 'all')[-1] for etype in g_hetero.etypes}\n",
    "\n",
    "sampler = HomoNeighborSampler([config['r1'],config['r2']], prefetch_node_feats=['feat'])\n",
    "sampler = HetEdgePredictionSampler(\n",
    "        sampler, g_homo = g_homo,\n",
    "        negative_sampler=dgl.dataloading.negative_sampler.Uniform(1))\n",
    "dataloader = dgl.dataloading.DataLoader(\n",
    "        g_hetero, edge_dict, sampler,\n",
    "        device=device, batch_size= config['batch_size'], shuffle=True,\n",
    "        drop_last=False, num_workers=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "best_loss = 100\n",
    "for epoch in range(10):\n",
    "    model.train()\n",
    "    t0 = time.time()\n",
    "    # with dataloader.enable_cpu_affinity():\n",
    "    with tqdm.tqdm(dataloader) as tq:\n",
    "        for it, (input_nodes, pair_graph, neg_pair_graph, blocks) in enumerate(tq):\n",
    "            tq.set_description('Epoch: {}'.format(epoch))\n",
    "            x = {'paper':blocks[0].srcdata['feat']}\n",
    "            pos_score, neg_score = model(pair_graph, neg_pair_graph, blocks, x)\n",
    "            pos_label = torch.ones_like(pos_score)\n",
    "            neg_label = torch.zeros_like(neg_score)\n",
    "            score = torch.cat([pos_score, neg_score])\n",
    "            labels = torch.cat([pos_label, neg_label])\n",
    "            loss = F.binary_cross_entropy_with_logits(score, labels)\n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            tq.set_postfix({'loss':'{:.3f}'.format(loss.item())})\n",
    "    model.eval()\n",
    "    val_loss, val_auc, _, _ = evaluate(model, g_hetero, val_pos_g, val_neg_g)\n",
    "    if val_loss < best_loss:\n",
    "        best_loss = val_loss\n",
    "        best_params = model.state_dict()\n",
    "    torch.save(best_params,params_path)\n",
    "print(\"Finished Training\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(best_params)\n",
    "\n",
    "with torch.no_grad():\n",
    "    emb = model.inference(g,device,4096,0,device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb = emb.detach().numpy().astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_dict = {}\n",
    "for i, data in node_df.iterrows():\n",
    "    emb_dict[data['paper_id']] = list(emb[i,:])\n",
    "emb_s = pd.Series(emb_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('graphsage_mean_{}.json'.format(year), 'w') as outfile: \n",
    "        json.dump(emb_s.to_dict(), outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
