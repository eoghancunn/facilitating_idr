{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "import string \n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import networkx as nx\n",
    "import seaborn as sns\n",
    "from scipy.spatial import distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json('../data/scopus_complete_metadata_final.jsonl',lines = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fields = ['title', 'year', 'abstract', 'citations.paperId', 'references.paperId', 'citationCount']\n",
    "paper_fields = '?fields=' + ','.join(fields)\n",
    "paper_url = 'https://api.semanticscholar.org/graph/v1/paper/{}'\n",
    "header = {'x-api-key': 'X2WAIqbVAQB6nWPCy7zL8XU3STL8gep9NY7eYHf0'} # S2 provide API keys for increased limits\n",
    "doi_list = [paper_id for paper_id in df['paperId'].dropna()]\n",
    "index_list = list(df['paperId'].dropna().index)\n",
    "batch_size = 50\n",
    "num_batches = int(len(doi_list)/batch_size)\n",
    "meta_data = []\n",
    "for batch_num in tqdm(range(num_batches)):\n",
    "    index = index_list[batch_num*batch_size:(batch_num+1)*batch_size]\n",
    "    query = {\"ids\": doi_list[batch_num*batch_size:(batch_num+1)*batch_size]}\n",
    "    url = paper_url.format('batch') + paper_fields\n",
    "    r = requests.post(url, json = query, headers = header)\n",
    "    res = json.loads(r.text)\n",
    "    for i in range(batch_size):\n",
    "        try:\n",
    "            if res[i]:\n",
    "                res[i].update({'original_index':index[i]})\n",
    "                meta_data.append(res[i])\n",
    "        except: \n",
    "            None "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# repeat for final batch\n",
    "if len(doi_list)%batch_size != 0:\n",
    "    index = index_list[(batch_num+1)*batch_size:len(doi_list)]\n",
    "    query = {\"ids\": doi_list[(batch_num+1)*batch_size:len(doi_list)]}\n",
    "    url = paper_url.format('batch') + paper_fields\n",
    "    r = requests.post(url, json = query, headers = header)\n",
    "    res = json.loads(r.text)\n",
    "    for i in range(len(res)):\n",
    "        if res[i]:\n",
    "            res[i].update({'original_index':index[i]})\n",
    "            meta_data.append(res[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(meta_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df = df.join(add_df.set_index('original_index'), rsuffix = '_add')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = full_df.loc[full_df['paperId'] == full_df['paperId_add']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_json('meta_data.jsonl', orient = 'records', lines = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.read_json('meta_data.jsonl', lines = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_ids = set(final_df['paperId'])\n",
    "final_df.loc[:,'in_set_refs'] = final_df['references'].map(lambda x: set(x).intersection(paper_ids))\n",
    "final_df.loc[:,'in_set_cits'] = final_df['citations'].map(lambda x: set(x).intersection(paper_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.loc[:,'adjacencies'] = final_df.apply(lambda row:\n",
    "                                              row['in_set_refs'].union(row['in_set_cits']),\n",
    "                                              axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_total = nx.Graph()\n",
    "for n1, data in final_df.set_index('paperId').iterrows():\n",
    "    G_total.add_node(n1, year = data['year'])\n",
    "for n1, data in final_df.set_index('paperId').iterrows():\n",
    "    for n2 in data['adjacencies']:\n",
    "        G_total.add_edge(n1, n2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_total.number_of_nodes(), G_total.number_of_edges()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subgraphs = {}\n",
    "for y in reversed(range(2014,2022)):\n",
    "    print(y)\n",
    "    subgraph = G_total.subgraph(\n",
    "        [node for node, year_attr in G_total.nodes(data='year')\n",
    "         if year_attr <= y])\n",
    "    subgraphs[y] = subgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subgraphs[2017].number_of_nodes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for y in subgraphs:\n",
    "    print(y, subgraphs[y].number_of_nodes(), subgraphs[y].number_of_edges())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('scibert_embeddings.json', 'w') as outfile: \n",
    "    json.dump(final_df.set_index('paperId')['scibert_cls'].to_dict(), outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.set_index('paperId')['scibert_cls'].to_json('scibert_embeddings.jsonl', orient = 'records', lines = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for y in subgraphs:\n",
    "    nx.write_gexf(subgraphs[y],'citation_graphs/{}.gexf'.format(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_i = nx.convert_node_labels_to_integers(subgraphs[2014], label_attribute = 'paperId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "G_i.nodes(data = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
